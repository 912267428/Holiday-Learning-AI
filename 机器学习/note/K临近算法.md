## k临近算法（KNN）：

K临近算法简单、直观。通过临近分类器来对待分类的数据进行分类。	

### 算法流程：

1. 根据给定的距离度量，在训练集中找出与样本最邻近的k个点，涵盖这k个点的 领域记作Nk(x)

2. 在领域中根据分类决策规则（如多数表决）决定样本点的类别 。

   

   

### 距离度量：

待分类数据与训练集中的数据的距离需要根据距离度量来确定。距离度量可以反映出两个实点之间的相似性程度。

1. 欧氏距离：最常见的两点之间或多点之间的距离表示法。可以用于多维距离度量
2. 曼哈顿距离：曼哈顿距离的正式意义为L1距离或城市区块距离，也就是在欧几里得空间的固定直角坐标系上两点所形成的线段对轴产生的投射的距离总和。
3. 夹角余弦：几何中夹角余弦可用来衡量两个向量方向的相似度，机器学习中借用这一概念来	衡量向量之间的相似度。

### K值的选择：

K值的选择会对K临近算法的结果产生巨大的影响。

如果K值较小，相当于用较小的领域中的训练实例进行预测。学校近似误差减小，估计误差增大，容易发生过拟合相当于把模型复杂化。

如果K值较大，相当于用较大的领域中的训练实例进行预测。近似误差会变大。相当于把模型简单化。如果K=N则结果一直是模型中最多的类。过于简单。
	   ==K一般低于训练样本数的平方根==



